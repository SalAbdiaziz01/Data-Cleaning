{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Task\n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import fuzzywuzzy\n","from fuzzywuzzy import process\n","import chardet"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 7 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   id             1000 non-null   int64 \n"," 1   store_name     1000 non-null   object\n"," 2   store_email    413 non-null    object\n"," 3   department     973 non-null    object\n"," 4   income         1000 non-null   object\n"," 5   date_measured  1000 non-null   object\n"," 6   country        965 non-null    object\n","dtypes: int64(1), object(6)\n","memory usage: 54.8+ KB\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>United States/</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>Britain</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>United States</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>Britain/</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                   store_name         store_email  department  \\\n","0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n","1   2          Nordson Corporation                 NaN       Tools   \n","2   3        Stag Industrial, Inc.                 NaN      Beauty   \n","3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n","4   5  Mercantile Bank Corporation                 NaN        Baby   \n","\n","         income date_measured          country  \n","0  $54438554.24      4-2-2006   United States/  \n","1  $41744177.01      4-1-2006          Britain  \n","2  $36152340.34     12-9-2003    United States  \n","3   $8928350.04      8-5-2006         Britain/  \n","4  $33552742.32     21-1-1973   United Kingdom  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Load up store_income_data.csv\n","df_income = pd.read_csv(\"store_income_data_task.csv\")\n","df_income.info()\n","df_income.head()"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 77 unique countries\n"]},{"data":{"text/plain":["array(['United States/', 'Britain', ' United States', 'Britain/',\n","       ' United Kingdom', 'U.K.', 'SA ', 'U.K/', 'America',\n","       'United Kingdom', nan, 'united states', ' S.A.', 'England ', 'UK',\n","       'S.A./', 'ENGLAND', 'BRITAIN', 'U.K', 'U.K ', 'America/', 'SA.',\n","       'S.A. ', 'u.k', 'uk', ' ', 'UK.', 'England/', 'england',\n","       ' Britain', 'united states of america', 'UK/', 'SA/', 'SA',\n","       'England.', 'UNITED KINGDOM', 'America.', 'S.A..', 's.a.', ' U.K',\n","       ' United States of America', 'Britain ', 'England', ' SA',\n","       'United States of America.', 'United States of America/',\n","       'United States.', 's. africasouth africa', ' England',\n","       'United Kingdom ', 'United States of America ', ' UK',\n","       'united kingdom', 'AMERICA', 'America ',\n","       'UNITED STATES OF AMERICA', ' S. AfricaSouth Africa', 'america',\n","       'S. AFRICASOUTH AFRICA', 'Britain.', '/', 'United Kingdom.',\n","       'United States', ' America', 'UNITED STATES', 'sa',\n","       'United States of America', 'UK ', 'United States ',\n","       'S. AfricaSouth Africa/', 'S.A.', 'United Kingdom/',\n","       'S. AfricaSouth Africa ', 'S. AfricaSouth Africa.',\n","       'S. AfricaSouth Africa', '.', 'britain'], dtype=object)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["countries = df_income['country'].unique()\n","print(f\"There are {len(countries)} unique countries\")\n","countries"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 3 unique countries\n","All done!\n","All done!\n","All done!\n","There are 3 unique countries\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Salman\\AppData\\Local\\Temp\\ipykernel_15216\\3554970827.py:55: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df_income.country.fillna('other', inplace=True)\n"]},{"data":{"text/plain":["array(['united states', 'united kingdom', 'south africa'], dtype=object)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["#Convert to lower case \n","df_income['country'] = df_income['country'].str.lower()\n","\n","# Remove trailing white spaces\n","df_income['country'] = df_income['country'].str.strip()\n","\n","# Let us view the data\n","countries = df_income['country'].unique()\n","print(f\"There are {len(countries)} unique countries\")\n","\n","# Function to replace rows in the provided column of the provided DataFrame\n","# that match the provided string above the provided ratio with the provided string\n","def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n","    # get a list of unique strings\n","    strings = df[column].unique()\n","    \n","    # Get the top 10 closest matches to our input string\n","    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n","                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","\n","    # Only get matches with a ratio > 90\n","    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n","\n","    # Get the rows of all the close matches in our dataframe\n","    rows_with_matches = df[column].isin(close_matches)\n","\n","    # Replace all rows with close matches with the input matches \n","    df.loc[rows_with_matches, column] = string_to_match\n","    \n","    # Let us know when the function is done\n","    print(\"All done!\")\n","\n","replace_matches_in_column(df=df_income, column='country', string_to_match=\"south africa\")\n","replace_matches_in_column(df=df_income, column='country', string_to_match=\"united kingdom\")\n","replace_matches_in_column(df=df_income, column='country', string_to_match=\"united states\")\n","\n","# 'South Africa', 'United Kingdom' and 'United States'\n","\n","#Manually cleaning (Want \"united kingdom\" and anything else is wrong)\n","mistype_uk = ['britain','britain/','u.k.','u.k/','england','u.k','uk.',\n","              'england/','uk/','england.','britain.','uk']\n","#replace('find','replace with')\n","df_income.replace(mistype_uk,'united kingdom',inplace=True)\n","\n","#Manually cleaning (Want \"united states\" and anything else is wrong)\n","mistype_usa = ['america','america/','united states of america','america.','united states of america.'\n","               'united states of america/','united states of america.','united states of america/']\n","df_income.replace(mistype_usa,'united states',inplace=True)\n","\n","mistype_sa = ['sa','s.a','s.a/','sa.','sa/','s.a..','s. africasouth africa',\n","              's. africasouth africa/','s. africasouth africa.','s.a.','s.a./',]\n","df_income.replace(mistype_sa,'south africa',inplace=True)\n","\n","mistype_other = ['','/','.']\n","df_income.country.fillna('other', inplace=True)\n","df_income.replace(mistype_other,'other',inplace=True)\n","\n","df_income = df_income[df_income['country'] != 'other']\n","df_income.reset_index(drop=True, inplace=True)\n","\n","countries = df_income['country'].unique()\n","print(f\"There are {len(countries)} unique countries\")\n","\n","countries\n"]},{"cell_type":"markdown","metadata":{},"source":["After cleaning my dataset the results are here\n","- The amount of country we have right now is **1000**\n","- The amount of country 'other is **86**\n","\n","Going to drop the 'other' which is about **8.6%** which I consider to be too significant but since the objective of the wants to only three country is 'South Africa', 'United Kingdom' and 'United States'"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('phd')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
